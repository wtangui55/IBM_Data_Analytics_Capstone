{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDA0321ENSkillsNetwork928-2022-01-01\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Wrangling Lab**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated time needed: **45 to 60** minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment you will be performing data wrangling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab you will perform the following:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Identify duplicate values in the dataset.\n",
    "\n",
    "-   Remove duplicate values from the dataset.\n",
    "\n",
    "-   Identify missing values in the dataset.\n",
    "\n",
    "-   Impute the missing values in the dataset.\n",
    "\n",
    "-   Normalize data in the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hands on Lab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import pandas module.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset into a dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/LargeData/m1_survey_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding duplicates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section you will identify duplicate values in the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Find how many duplicate rows exist in the dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 154\n"
     ]
    }
   ],
   "source": [
    "# Counts duplicate rows, prints'Nummber of duplicate rows:' and displays the number of duplicate rows\n",
    "duplicate_rows = df.duplicated().sum()\n",
    "print(\"Number of duplicate rows:\", duplicate_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate entries in 'Respondent': 154\n"
     ]
    }
   ],
   "source": [
    "# Count the number of duplicate entries in the 'Respondent' column\n",
    "duplicate_respondents = df['Respondent'].duplicated().sum()\n",
    "print(\"Number of duplicate entries in 'Respondent':\", duplicate_respondents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing duplicates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows in teh dataset: 11552\n"
     ]
    }
   ],
   "source": [
    "num_rows = df.shape[0]\n",
    "print(\"number of rows in teh dataset:\", num_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the duplicate rows from the dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Removes duplicate rows\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify if duplicates were actually dropped.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows after removal: 0\n"
     ]
    }
   ],
   "source": [
    "# Verifies if duplicates were actually dropped\n",
    "duplicate_rows_after = df.duplicated().sum()\n",
    "#pritns 'Number of duplicate rows after removal:\" and displays the number  of duplicates after removal\n",
    "print(\"Number of duplicate rows after removal:\", duplicate_rows_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows in the dataset afteer duplicate removal: 11398\n",
      "Number of rows in Respondent Column After Duplicate Removal: 11398\n"
     ]
    }
   ],
   "source": [
    "num_rows_after = df.shape[0]\n",
    "print(\"number of rows in the dataset afteer duplicate removal:\", num_rows_after)\n",
    "unique_respondent_after = df['Respondent'].nunique()\n",
    "print(\"Number of rows in Respondent Column After Duplicate Removal:\", unique_respondent_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Missing values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the missing values for all columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Respondent                   0\n",
       "MainBranch                   0\n",
       "Hobbyist                     0\n",
       "OpenSourcer                  0\n",
       "OpenSource                  81\n",
       "Employment                   0\n",
       "Country                      0\n",
       "Student                     51\n",
       "EdLevel                    112\n",
       "UndergradMajor             737\n",
       "EduOther                   164\n",
       "OrgSize                     96\n",
       "DevType                     65\n",
       "YearsCode                    9\n",
       "Age1stCode                  13\n",
       "YearsCodePro                16\n",
       "CareerSat                    0\n",
       "JobSat                       1\n",
       "MgrIdiot                   493\n",
       "MgrMoney                   497\n",
       "MgrWant                    493\n",
       "JobSeek                      0\n",
       "LastHireDate                 0\n",
       "LastInt                    413\n",
       "FizzBuzz                    37\n",
       "JobFactors                   3\n",
       "ResumeUpdate                39\n",
       "CurrencySymbol               0\n",
       "CurrencyDesc                 0\n",
       "CompTotal                  809\n",
       "CompFreq                   206\n",
       "ConvertedComp              816\n",
       "WorkWeekHrs                122\n",
       "WorkPlan                   121\n",
       "WorkChallenge              164\n",
       "WorkRemote                   8\n",
       "WorkLoc                     32\n",
       "ImpSyn                       5\n",
       "CodeRev                      1\n",
       "CodeRevHrs                2426\n",
       "UnitTests                   29\n",
       "PurchaseHow                196\n",
       "PurchaseWhat                38\n",
       "LanguageWorkedWith          11\n",
       "LanguageDesireNextYear     134\n",
       "DatabaseWorkedWith         453\n",
       "DatabaseDesireNextYear    1042\n",
       "PlatformWorkedWith         411\n",
       "PlatformDesireNextYear     544\n",
       "WebFrameWorkedWith        1393\n",
       "WebFrameDesireNextYear    1617\n",
       "MiscTechWorkedWith        2182\n",
       "MiscTechDesireNextYear    1455\n",
       "DevEnviron                  29\n",
       "OpSys                       34\n",
       "Containers                  82\n",
       "BlockchainOrg             2322\n",
       "BlockchainIs              2610\n",
       "BetterLife                  98\n",
       "ITperson                    35\n",
       "OffOn                       38\n",
       "SocialMedia                293\n",
       "Extraversion                20\n",
       "ScreenName                 507\n",
       "SOVisit1st                 325\n",
       "SOVisitFreq                  5\n",
       "SOVisitTo                    1\n",
       "SOFindAnswer                 3\n",
       "SOTimeSaved                 50\n",
       "SOHowMuchTime             1917\n",
       "SOAccount                    1\n",
       "SOPartFreq                1128\n",
       "SOJobs                       6\n",
       "EntTeams                     5\n",
       "SOComm                       0\n",
       "WelcomeChange               85\n",
       "SONewContent              1965\n",
       "Age                        287\n",
       "Gender                      73\n",
       "Trans                      123\n",
       "Sexuality                  542\n",
       "Ethnicity                  675\n",
       "Dependents                 140\n",
       "SurveyLength                19\n",
       "SurveyEase                  14\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finds missing values for all columns\n",
    "missing_values = df.isnull().sum()\n",
    "# Sets the option to display all rows/columns \n",
    "pd.set_option('display.max_rows', None)  # for rows\n",
    "pd.set_option('display.max_columns', None)  # for columns\n",
    "pd.set_option('display.max_colwidth', None)  # for column width\n",
    "# Displays missing values\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find out how many rows are missing in the column 'WorkLoc'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing rows in 'WorkLoc': 32\n"
     ]
    }
   ],
   "source": [
    "# Finds out how many rows are missing in the column 'WorkLoc'\n",
    "missing_workloc = df['WorkLoc'].isnull().sum()\n",
    "# Prints 'Missing rows in WorkLoc' then displaycs the missing values of 'Workloc'\n",
    "print(\"Missing rows in 'WorkLoc':\", missing_workloc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputing missing values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the  value counts for the column WorkLoc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Office                                            6806\n",
      "Home                                              3589\n",
      "Other place, such as a coworking space or cafe     971\n",
      "Name: WorkLoc, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Value counts for the column 'WorkLoc'\n",
    "workloc_counts = df['WorkLoc'].value_counts()\n",
    "print(workloc_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify the value that is most frequent (majority) in the WorkLoc column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority value in WorkLoc: Office\n"
     ]
    }
   ],
   "source": [
    "# Identifies the majority value\n",
    "majority_value = workloc_counts.idxmax()\n",
    "print(\"Majority value in WorkLoc:\", majority_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Employed full-time    10968\n",
      "Employed part-time      430\n",
      "Name: Employment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Value counts for the column 'Employment'\n",
    "workloc_counts = df['Employment'].value_counts()\n",
    "print(workloc_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computer science, computer engineering, or software engineering          6953\n",
      "Information systems, information technology, or system administration     794\n",
      "Another engineering discipline (ex. civil, electrical, mechanical)        759\n",
      "Web development or web design                                             410\n",
      "A natural science (ex. biology, chemistry, physics)                       403\n",
      "Mathematics or statistics                                                 372\n",
      "A business discipline (ex. accounting, finance, marketing)                244\n",
      "A social science (ex. anthropology, psychology, political science)        210\n",
      "A humanities discipline (ex. literature, history, philosophy)             207\n",
      "Fine arts or performing arts (ex. graphic design, music, studio art)      161\n",
      "I never declared a major                                                  124\n",
      "A health science (ex. nursing, pharmacy, radiology)                        24\n",
      "Name: UndergradMajor, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Value counts for the column 'UndergradMajor'\n",
    "workloc_counts = df['UndergradMajor'].value_counts()\n",
    "print(workloc_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yearly     6073\n",
      "Monthly    4788\n",
      "Weekly      331\n",
      "Name: CompFreq, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Value counts for the column 'CompFreq'\n",
    "workloc_counts = df['CompFreq'].value_counts()\n",
    "print(workloc_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impute (replace) all the empty rows in the column WorkLoc with the value that you have identified as majority.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imputes missing values in WorkLoc\n",
    "df['WorkLoc'].fillna(majority_value, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After imputation there should ideally not be any empty rows in the WorkLoc column.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify if imputing was successful.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing rows in 'WorkLoc' after imputation: 0\n"
     ]
    }
   ],
   "source": [
    "# Verifies the imputation\n",
    "missing_workloc_after = df['WorkLoc'].isnull().sum()\n",
    "print(\"Missing rows in 'WorkLoc' after imputation:\", missing_workloc_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two columns in the dataset that talk about compensation.\n",
    "\n",
    "One is \"CompFreq\". This column shows how often a developer is paid (Yearly, Monthly, Weekly).\n",
    "\n",
    "The other is \"CompTotal\". This column talks about how much the developer is paid per Year, Month, or Week depending upon his/her \"CompFreq\". \n",
    "\n",
    "This makes it difficult to compare the total compensation of the developers.\n",
    "\n",
    "In this section you will create a new column called 'NormalizedAnnualCompensation' which contains the 'Annual Compensation' irrespective of the 'CompFreq'.\n",
    "\n",
    "Once this column is ready, it makes comparison of salaries easy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List out the various categories in the column 'CompFreq'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yearly     6073\n",
      "Monthly    4788\n",
      "Weekly      331\n",
      "Name: CompFreq, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Creates a Series object that counts the occurence of each unique value\n",
    "compfreq_categories = df['CompFreq'].value_counts()\n",
    "print(compfreq_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Yearly' 'Monthly' 'Weekly' nan]\n"
     ]
    }
   ],
   "source": [
    "unique_values = df['CompFreq'].unique()\n",
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new column named 'NormalizedAnnualCompensation'. Use the hint given below if needed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double click to see the **Hint**.\n",
    "\n",
    "<!--\n",
    "\n",
    "Use the below logic to arrive at the values for the column NormalizedAnnualCompensation.\n",
    "\n",
    "If the CompFreq is Yearly then use the exising value in CompTotal\n",
    "If the CompFreq is Monthly then multiply the value in CompTotal with 12 (months in an year)\n",
    "If the CompFreq is Weekly then multiply the value in CompTotal with 52 (weeks in an year)\n",
    "\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CompFreq  CompTotal  NormalizedAnnualCompensation\n",
      "0   Yearly    61000.0                       61000.0\n",
      "1   Yearly   138000.0                      138000.0\n",
      "2   Yearly    90000.0                       90000.0\n",
      "3  Monthly    29000.0                      348000.0\n",
      "4   Yearly    90000.0                       90000.0\n"
     ]
    }
   ],
   "source": [
    "# Creates function to normalize compensation\n",
    "def normalize_compensation(row):\n",
    "    if row['CompFreq'] == 'Monthly':\n",
    "        return row['CompTotal'] * 12\n",
    "    elif row['CompFreq'] == 'Weekly':\n",
    "        return row['CompTotal'] * 52\n",
    "    else:\n",
    "        return row['CompTotal']\n",
    "\n",
    "# Applies the function\n",
    "df['NormalizedAnnualCompensation'] = df.apply(normalize_compensation, axis=1)\n",
    "\n",
    "# Checks the new column\n",
    "print(df[['CompFreq', 'CompTotal', 'NormalizedAnnualCompensation']].head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000.0\n"
     ]
    }
   ],
   "source": [
    "median_normalized_annual_compensation = df['NormalizedAnnualCompensation'].median()\n",
    "print(median_normalized_annual_compensation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ramesh Sannareddy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Contributors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rav Ahuja\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Date (YYYY-MM-DD) | Version | Changed By        | Change Description                 |\n",
    "| ----------------- | ------- | ----------------- | ---------------------------------- |\n",
    "| 2020-10-17        | 0.1     | Ramesh Sannareddy | Created initial version of the lab |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Copyright Â© 2020 IBM Corporation. This notebook and its source code are released under the terms of the [MIT License](https://cognitiveclass.ai/mit-license?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDA0321ENSkillsNetwork928-2022-01-01&cm_mmc=Email_Newsletter-_-Developer_Ed%2BTech-_-WW_WW-_-SkillsNetwork-Courses-IBM-DA0321EN-SkillsNetwork-21426264&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
